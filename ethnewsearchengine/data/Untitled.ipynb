{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import re\n",
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "docs=[]\n",
    "with open('data.json') as f:\n",
    "    data = json.load(f)\n",
    "count=0\n",
    "for each in data:\n",
    "    count+=1\n",
    "    docs.append(each['title'])\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',strip_accents='unicode',encoding='utf-8', decode_error='ignore')\n",
    "temp = vectorizer.fit(docs)\n",
    "temp2 = vectorizer.transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3385)\t0.05369452820101016\n",
      "  (0, 3112)\t0.23534711612929818\n",
      "  (0, 2605)\t0.2913921424224474\n",
      "  (0, 2270)\t0.21123395680454554\n",
      "  (0, 2214)\t0.2913921424224474\n",
      "  (0, 1972)\t0.2503999200695356\n",
      "  (0, 1916)\t0.24224337593365833\n",
      "  (0, 1741)\t0.11098649653956141\n",
      "  (0, 1291)\t0.06033441403613629\n",
      "  (0, 1245)\t0.2503999200695356\n",
      "  (0, 1208)\t0.2732527950627711\n",
      "  (0, 1173)\t0.2603827232933346\n",
      "  (0, 702)\t0.2913921424224474\n",
      "  (0, 554)\t0.2732527950627711\n",
      "  (0, 375)\t0.23534711612929818\n",
      "  (0, 333)\t0.2913921424224474\n",
      "  (0, 153)\t0.2913921424224474\n",
      "  (1, 3481)\t0.3768285506425073\n",
      "  (1, 3111)\t0.4018435700628122\n",
      "  (1, 3028)\t0.4018435700628122\n",
      "  (1, 1916)\t0.3340650924901203\n",
      "  (1, 1291)\t0.1664080309947379\n",
      "  (1, 1132)\t0.3590801119104251\n",
      "  (1, 375)\t0.3245548234868911\n",
      "  (1, 272)\t0.4018435700628122\n",
      "  :\t:\n",
      "  (493, 841)\t0.1808725622155888\n",
      "  (493, 608)\t0.38883284331073736\n",
      "  (493, 367)\t0.08860881528227592\n",
      "  (493, 80)\t0.13320221293403042\n",
      "  (493, 71)\t0.2040259428563695\n",
      "  (493, 40)\t0.18696269793548023\n",
      "  (493, 38)\t0.1808725622155888\n",
      "  (493, 20)\t0.1525700451919805\n",
      "  (494, 3486)\t0.41133383213641067\n",
      "  (494, 3385)\t0.05719055574149518\n",
      "  (494, 3380)\t0.3103645589632197\n",
      "  (494, 3154)\t0.200646492686199\n",
      "  (494, 3021)\t0.22913339632825697\n",
      "  (494, 2902)\t0.3103645589632197\n",
      "  (494, 2621)\t0.20839051167258157\n",
      "  (494, 2153)\t0.21764203619835518\n",
      "  (494, 2119)\t0.2910441665313444\n",
      "  (494, 1741)\t0.05910638969707564\n",
      "  (494, 1500)\t0.2910441665313444\n",
      "  (494, 1292)\t0.104636462992935\n",
      "  (494, 1291)\t0.1285255233511554\n",
      "  (494, 1228)\t0.2773361299475878\n",
      "  (494, 1225)\t0.18634652363633006\n",
      "  (494, 991)\t0.23367492170183093\n",
      "  (494, 30)\t0.2910441665313444\n"
     ]
    }
   ],
   "source": [
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(temp, open(\"vectorizer.pickle\", \"wb\"))\n",
    "pickle.dump(temp2, open(\"tfidf.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvectorizer = pickle.load(open(\"vectorizer.pickle\", \"rb\"))\n",
    "tfidf = pickle.load(open(\"tfidf.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 32, 33, 36, 25, 26, 11, 19, 20, 23, 53, 74, 82, 143, 164, 166, 167, 168, 169, 170, 173, 163, 159, 160, 162, 247, 288, 305, 424, 430, 434, 435, 439, 440]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import operator\n",
    "query_string = [\"minster ofice\"]\n",
    "query = 'boeing'\n",
    "re_item = query \n",
    "\n",
    "#tfidf\n",
    "query_vec = myvectorizer.transform(query_str)\n",
    "cosine_similarities = linear_kernel(query, tfidf).flatten()\n",
    "related_docs_indices = cosine_similarities.argsort()[:-20:-1]\n",
    "res = [i for i in related_docs_indices if (cosine_similarities[i] > 0)]\n",
    "\n",
    "#regular expression\n",
    "for i,each in enumerate(data): \n",
    "    if re.search(re_item, each['name'], flags=re.IGNORECASE):\n",
    "            res.append(i)\n",
    "    for word in each['name'].split(' '):\n",
    "        for look in query.split(' '):\n",
    "            if re.search(look, word, flags=re.IGNORECASE):\n",
    "                res.append(i)\n",
    "                \n",
    "for i,each in enumerate(data): \n",
    "    if re.search(re_item, each['title'], flags=re.IGNORECASE):\n",
    "            res.append(i)\n",
    "    for word in each['title'].split(' '):\n",
    "        for look in query.split(' '):\n",
    "            if re.search(look, word, flags=re.IGNORECASE):\n",
    "                res.append(i)                \n",
    "res = list(dict.fromkeys(filtered_docs_indices))\n",
    "\n",
    "if len(filtered_docs_indices) == 0:\n",
    "    query_string = [spell(query)]\n",
    "    re_item = spell(query)\n",
    "    query_vec = myvectorizer.transform(query_string)\n",
    "    cosine_similarities = linear_kernel(query_vec, tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-21:-1]\n",
    "    filtered_docs_indices = [i for i in related_docs_indices if (cosine_similarities[i] > 0)]\n",
    "    for i,each in enumerate(data): \n",
    "        if re.search(re_item, each['name'], flags=re.IGNORECASE):\n",
    "                filtered_docs_indices.append(i)\n",
    "        for word in each['name'].split(' '):\n",
    "            for look in query.split(' '):\n",
    "                if re.search(look, word, flags=re.IGNORECASE):\n",
    "                    filtered_docs_indices.append(i)\n",
    "    for i,each in enumerate(data): \n",
    "        if re.search(re_item, each['title'], flags=re.IGNORECASE):\n",
    "                filtered_docs_indices.append(i)\n",
    "        for word in each['title'].split(' '):\n",
    "            for look in query.split(' '):\n",
    "                if re.search(look, word, flags=re.IGNORECASE):\n",
    "                    filtered_docs_indices.append(i) \n",
    "\n",
    "#consider follower and time\n",
    "list_time_follower = []\n",
    "list_time = []\n",
    "list_follower = []\n",
    "for i in filtered_docs_indices:\n",
    "    list_time.append(data[i]['url'][2])\n",
    "for i in filtered_docs_indices:\n",
    "    list_follower.append(data[i]['followers_count'])\n",
    "\n",
    "normed_time = [i/sum(list_time) for i in list_time]\n",
    "normed_time = [x * 2 for x in normed_time]\n",
    "normed_followers = [i/sum(list_follower) for i in list_follower]\n",
    "\n",
    "\n",
    "lst= list(map(operator.add, normed_time,normed_followers))\n",
    "\n",
    "order=[]\n",
    "for idx, i in enumerate(filtered_docs_indices):\n",
    "    order.append([i,lst[idx]])\n",
    "\n",
    "order= sorted(order, key=itemgetter(1),reverse=True)\n",
    "order2 = [item[0] for item in order]\n",
    "print(order2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filtered_docs_indices:\n",
    "    print(data[i]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
